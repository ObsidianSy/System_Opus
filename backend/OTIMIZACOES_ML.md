# üöÄ Otimiza√ß√µes do IMPORT ML - System Opus

## üìä Problema Identificado
- **Antes**: Upload de 6367 linhas salvou apenas 27 (99.6% de perda)
- **Causa**: Loop com INSERTs individuais causou timeout HTTP
- **Impacto**: Usu√°rio n√£o conseguia importar planilhas grandes do Mercado Livre

---

## ‚úÖ Solu√ß√µes Implementadas

### 1Ô∏è‚É£ **BULK INSERT - Performance Cr√≠tica**
**Arquivo**: `backend/src/routes/envios.ts` (linhas ~728-920)

#### ANTES (‚ùå LENTO):
```typescript
// 6367 chamadas individuais ao banco = MUITO LENTO
for (let i = 0; i < jsonData.length; i++) {
    await pool.query(`INSERT INTO raw_export_orders VALUES (...)`, [...85 colunas]);
}
```

#### DEPOIS (‚úÖ R√ÅPIDO):
```typescript
// 1. Preparar TODOS os dados em mem√≥ria (sem DB calls)
const valuesToInsert = [];
for (let i = 0; i < jsonData.length; i++) {
    valuesToInsert.push([...data]);
}

// 2. Inserir em BATCHES de 500 linhas
const BATCH_SIZE = 500;
for (let i = 0; i < valuesToInsert.length; i += BATCH_SIZE) {
    const batch = valuesToInsert.slice(i, i + BATCH_SIZE);
    // Gerar placeholders dinamicamente ($1,$2,$3...)
    const placeholders = batch.map((_, idx) => 
        `($${idx * 85 + 1}, $${idx * 85 + 2}, ... $${idx * 85 + 85})`
    ).join(',');
    
    await pool.query(
        `INSERT INTO raw_export_orders VALUES ${placeholders}`,
        batch.flat()
    );
}
```

**Ganho de Performance**:
- 6367 chamadas ‚Üí 13 chamadas (6367 / 500 = 13 batches)
- **Redu√ß√£o de 99.8% nas chamadas ao banco**
- Upload que demorava minutos ‚Üí segundos

---

### 2Ô∏è‚É£ **AUTO-RELACIONAMENTO em BATCHES**
**Arquivo**: `backend/src/routes/envios.ts` (linhas ~870-930)

#### Problema:
- Processar 6367 linhas uma a uma para relacionar SKUs era lento
- Cada linha faz 1-3 queries (produtos + aliases + update)

#### Solu√ß√£o:
```typescript
// Processar em batches de 100 linhas com log de progresso
const RELATE_BATCH_SIZE = 100;
for (let i = 0; i < pendingRows.rows.length; i += RELATE_BATCH_SIZE) {
    const batch = pendingRows.rows.slice(i, i + RELATE_BATCH_SIZE);
    console.log(`üîç Relacionando batch ${Math.floor(i/100) + 1}/64 (100 linhas)...`);
    
    for (const row of batch) {
        // Buscar em produtos e aliases
        // ...relacionar se encontrar match
    }
}
```

**Benef√≠cios**:
- Usu√°rio v√™ progresso no console
- Previne timeout em uploads grandes
- Permite retry em caso de falha parcial

---

### 3Ô∏è‚É£ **LIMITE 1000 no Auto-Relacionamento Inicial**
**Arquivo**: `backend/src/routes/envios.ts` (linha ~845)

```typescript
const pendingRows = await pool.query(
    `SELECT id, sku_text 
     FROM raw_export_orders 
     WHERE import_id = $1 AND status = 'pending'
     LIMIT 1000`, // ‚ö†Ô∏è LIMITE para n√£o dar timeout
    [batchId]
);
```

**Motivo**:
- Se usu√°rio subir 10.000 linhas, auto-relacionar todas pode demorar muito
- Limite de 1000 garante que upload complete r√°pido
- Usu√°rio pode usar o bot√£o "Auto-Relacionar" depois para processar o resto

---

### 4Ô∏è‚É£ **Client_id: Nome ‚Üí ID Conversion**
**Arquivo**: `backend/src/routes/envios.ts` (linha ~1323)

#### Problema:
Frontend enviava: `client_id: "New Seven"` (nome)  
Backend esperava: `client_id: 123` (numeric ID)

#### Solu√ß√£o:
```typescript
let clientIdNum = clientId;

// Se recebeu nome ao inv√©s de ID, converter
if (isNaN(Number(clientId))) {
    const clientResult = await pool.query(
        `SELECT id FROM obsidian.clientes WHERE nome_fantasia ILIKE $1 LIMIT 1`,
        [clientId]
    );
    if (clientResult.rows.length === 0) {
        return res.status(400).json({ error: `Cliente "${clientId}" n√£o encontrado` });
    }
    clientIdNum = clientResult.rows[0].id;
}
```

---

### 5Ô∏è‚É£ **Fix: Remover client_id de Query de Produtos**
**Locais**: Linhas ~555, ~850

#### Problema:
```sql
-- ‚ùå ERRADO: produtos n√£o tem coluna client_id
SELECT sku FROM obsidian.produtos WHERE client_id = $1 AND sku = $2
```

#### Solu√ß√£o:
```sql
-- ‚úÖ CORRETO: produtos √© tabela global (sem client_id)
SELECT sku FROM obsidian.produtos WHERE UPPER(sku) = UPPER(TRIM($1))
```

---

### 6Ô∏è‚É£ **Fix: Bot√£o Auto-Relacionar (500 Error)**
**Arquivo**: `backend/src/routes/envios.ts` (linha ~1350)

#### Problema:
```sql
-- ‚ùå Coluna order_id n√£o existe
SELECT order_id as codigo_ml, qty FROM raw_export_orders WHERE ...
```

#### Solu√ß√£o:
```sql
-- ‚úÖ Usar colunas corretas
SELECT id, sku_text, client_id FROM raw_export_orders WHERE status = 'pending'
```

---

## üìà Resultados Esperados

### Performance:
- **Upload 6367 linhas**: ~27 segundos (antes: timeout ap√≥s 27 linhas)
- **Auto-relacionamento**: 1000 linhas em ~30-60 segundos
- **Bulk insert**: 500 linhas por batch = ~13 batches para 6367 linhas

### Funcionalidades Corrigidas:
- ‚úÖ Upload de planilhas grandes (5000+ linhas)
- ‚úÖ Auto-relacionamento durante upload (1000 primeiras)
- ‚úÖ Bot√£o "Auto-Relacionar" funcional (resto das linhas)
- ‚úÖ Valida√ß√£o de cliente por nome ou ID
- ‚úÖ Logs de progresso no console

---

## üö® PR√ìXIMOS PASSOS

### 1. Commitar as mudan√ßas:
```bash
git add backend/src/routes/envios.ts
git commit -m "feat(ml): bulk insert optimization + auto-relate fixes + client validation"
git push origin main
```

### 2. Redeploy no Easypanel:
- Ir no painel do Easypanel
- Selecionar o servi√ßo backend
- Clicar em "Rebuild" ou esperar auto-deploy

### 3. Testar Upload:
- Fazer upload da planilha de 6367 linhas novamente
- Verificar no console os logs de progresso dos batches
- Conferir se todas as linhas foram salvas

### 4. Verificar Auto-Relacionamento:
```sql
-- Ver quantas foram relacionadas automaticamente
SELECT status, COUNT(*) 
FROM raw_export_orders 
WHERE import_id = 'SEU_BATCH_ID' 
GROUP BY status;

-- Resultado esperado:
-- matched: ~80-90% (se SKUs estiverem no sistema)
-- pending: ~10-20% (SKUs novos que precisam relacionamento manual)
```

---

## üîç Monitoramento

### Logs a observar no upload:
```
üì¶ Preparando dados para inser√ß√£o...
üíæ Inserindo batch 1/13 (500 linhas)...
üíæ Inserindo batch 2/13 (500 linhas)...
...
üíæ Inserindo batch 13/13 (367 linhas)...
‚úÖ Total inserido: 6367 linhas (0 puladas)
üì¶ Processando 1000 linhas para auto-relacionamento em batches...
üîç Relacionando batch 1/10 (100 linhas)...
...
‚úÖ Auto-relacionamento conclu√≠do: 850 itens relacionados
```

---

## üìù Notas T√©cnicas

### Por que 500 linhas por batch?
- Balan√ßo entre performance e mem√≥ria
- PostgreSQL tem limite de ~65535 par√¢metros por query
- 85 colunas √ó 500 linhas = 42500 par√¢metros (seguro)

### Por que auto-relacionar apenas 1000?
- Upload precisa ser r√°pido para dar feedback ao usu√°rio
- Auto-relacionar 6000+ linhas pode demorar 3-5 minutos
- Melhor: upload r√°pido (1min) + bot√£o manual para o resto

### Performance Esperada:
- **Upload**: ~3-5 segundos por batch de 500 linhas
- **Auto-relacionamento**: ~0.5-1 segundo por linha (depende dos aliases)
- **Total para 6367 linhas**: ~1-2 minutos (upload + auto-relate 1000)

---

## ‚ö†Ô∏è Troubleshooting

### Se upload ainda der timeout:
1. Aumentar timeout do servidor (nginx/easypanel):
   ```nginx
   proxy_read_timeout 300s;
   ```

2. Reduzir BATCH_SIZE de 500 para 250:
   ```typescript
   const BATCH_SIZE = 250;
   ```

### Se auto-relacionamento travar:
1. Reduzir RELATE_BATCH_SIZE de 100 para 50
2. Adicionar √≠ndice na tabela produtos:
   ```sql
   CREATE INDEX IF NOT EXISTS idx_produtos_sku_upper 
   ON obsidian.produtos (UPPER(sku));
   ```

### Se encontrar linhas duplicadas:
```sql
-- Verificar duplicatas
SELECT order_id, COUNT(*) 
FROM raw_export_orders 
WHERE import_id = 'SEU_BATCH_ID' 
GROUP BY order_id 
HAVING COUNT(*) > 1;
```

---

**Data**: 2025
**Vers√£o**: 1.0
**Status**: ‚úÖ Pronto para deploy
